{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we would focus about Eclat Algorithm for frequency set mining.\n",
    "\n",
    "<h3>Association Rule Mining</h3>\n",
    "\n",
    "Association rule mining is used to determine meaningful relationships or frequent co-occuring associations between variables in a database. The most common application of Association rule mining is Market Basket Analysis which is intended to find the most frequently purchased items.This data would allow the business to understand buying patterns which in turn would help them in cross-selling, promotions, loyalty etc.\n",
    "\n",
    "This algorithm is also extensively used in other real world applications.<br>\n",
    "For example: In Customer Relationship Management, customer segmentations and niche marketing can be carried out with the help of association rules derived from the dataset.<br>\n",
    "We can group customers with similar preferences(say, similar preferences in mobile apps) and direct different promotions according to the segment(say, for gamers we could send apps more pertaining to the game domain). This increases customer retention and loyalty which inturn increases revenue.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation:\n",
    "\n",
    "Installation of Graphviz:\n",
    "Use the command:\n",
    "\n",
    "`pip install graphviz` \n",
    "\n",
    "After installing Graphviz, make sure that its <font color='red'>bin/ </font> subdirectory containing the layout commands for rendering graph descriptions (dot, circo, neato, etc.) is on your systems’ path. For further queries, please use the link mentioned as the second reference at the end of this tutorial.\n",
    "\n",
    "Note: If the above does not work try <font color='red'>conda install graphviz  </font>\n",
    "\n",
    "### Datset:\n",
    "Use test.csv that is a part of the handin.tar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from graphviz import Digraph\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general transaction data has a horizontal layout with transanctions followed by the item list pertaining to this transaction. Eclat algorithm works on vertical data layout/t-id sets where each item is associated with the transactions it has occured in. For this tutorial,we take a simple dataset with 7 transactions. A simple dataset is chosen here in order to understand the step by step working of Eclat algorithm and also to represent a DFS tree that is easier to interpret.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Transaction | Item List |\n",
    "| -- | --- |\n",
    "| 1 | milk |\n",
    "| 2 | milk,bread,jam,butter |\n",
    "| 3 | bread,jam |\n",
    "| 4 | bread,butter,jam |\n",
    "| 5 | milk,butter |\n",
    "| 6 | milk,bread,marmalade,jam |\n",
    "| 7 | bread,jam,spoon |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given csv file transaction data\n",
      "[Transaction,Item_List]\n",
      "['1', 'milk']\n",
      "['2', 'milk', 'bread', 'jam', 'butter']\n",
      "['3', 'bread', 'jam']\n",
      "['4', 'bread', 'butter', 'jam']\n",
      "['5', 'milk', 'butter']\n",
      "['6', 'milk', 'bread', 'marmalade', 'jam']\n",
      "['7', 'bread', 'jam', 'spoon']\n"
     ]
    }
   ],
   "source": [
    "print(\"Given csv file transaction data\")\n",
    "print(\"[Transaction,Item_List]\")\n",
    "data_size=0\n",
    "with open('test.csv',encoding='utf-8') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            print(row)\n",
    "            data_size = data_size+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of a vertical data set from horizontal data set:\n",
      "The underlying item-transaction file is:\n",
      "milk ['1', '2', '5', '6']\n",
      "bread ['2', '3', '4', '6', '7']\n",
      "jam ['2', '3', '4', '6', '7']\n",
      "butter ['2', '4', '5']\n",
      "marmalade ['6']\n",
      "spoon ['7']\n"
     ]
    }
   ],
   "source": [
    "print(\"Creation of a vertical data set from horizontal data set:\")\n",
    "item_list={}\n",
    "with open('test.csv',encoding='utf-8') as csvfile:\n",
    "     spamreader = csv.reader(csvfile)\n",
    "     for row in spamreader:\n",
    "       # print(row)\n",
    "        i=1\n",
    "        for i in range(1,len(row)):\n",
    "            if row[i] in item_list.keys():\n",
    "                item_list[row[i]].append(row[0])\n",
    "            else:\n",
    "                \n",
    "                item_list[row[i]] = [row[0]]\n",
    "print(\"The underlying item-transaction file is:\")\n",
    "for it,trans in item_list.items():\n",
    "            print(it,trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARM Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support and Confidence: \n",
    "Support of an association rule is defined as the percentage/fraction of records that contain the itemset X ∪ Y to the total number of records in the database. It determines how frequent this itemset is\n",
    "\n",
    "$$s(X→Y) = \\sigma(X \\cup Y)/N$$\n",
    "\n",
    "Confidence of an association rule is defined as the percentage/fraction of the number of transactions that contain X∪Y to the total number of records that contain X. This suggests how likely it is that Y is purchased when X is purchased.\n",
    "\n",
    "$$c(X→Y) = \\sigma(X \\cup Y)/\\sigma(X)$$         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARM Procedure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association Rule Mining has two major steps:\n",
    "\n",
    "1) <b> Generation of frequent item sets:</b> Itemsets(collection of one or more items) whose support is greater than a specified threshold called the minimum-support.\n",
    "\n",
    "2) <b> Generation of association rules:</b> These rules will specify the purchase patterns and is formed with the frequent itemsets that are generated in step1.Those rules that satisfy a minimum-confidence threshold are considered the rules for this market basket data.\n",
    "\n",
    "The threshold values will depend on the dataset and also on the underlying application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter minimum support for the dataset:0.285\n"
     ]
    }
   ],
   "source": [
    "min_sup=float(input(\"Enter minimum support for the dataset:\"))\n",
    "#feed value used = 0.285 [In order to observe 3-frequent itemsets also]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum support: 0.285\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum support:\",(min_sup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECLAT Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Eclat algorithm is a Depth First Search algorithm that uses the vertical dataset layout.\n",
    "\n",
    "This algorithm generates frequent itemsets using these two steps:\n",
    "\n",
    "1) <b>Candidate Generation</b>\n",
    "\n",
    "2) <b>Pruning</b>\n",
    "\n",
    "Before we understand the implementation of Eclat, we need to understand two major properties that ECLAT algorithm uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class to hold equivalence class item sets and associated prefix at every depth\n",
    "class E:\n",
    "    def __init__(self,item_set, prefix):\n",
    "        self.prefix = prefix\n",
    "        self.item_set = item_set\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Eclat:\n",
    "1)<b> Equivalence Class and Prefix:</b>\n",
    "An equivalence class of k-itemsets is a set of k-itemsets in the depth first search tree with k-1 items as common prefix\n",
    "\n",
    "$$E = ((i1,t(i1\\cup P)),...,(ik,t(ik\\cup P))|P) where i1,...,ik \\not\\in P $$ are itemsets with P as prefix<br>\n",
    "\n",
    "For example: If itemsets are (a,b,c,d,e) an equivalence class with prefix a is denoted as (b,c,d,e|a) where the itemsets are {ab,ac,ad,ae}<br>\n",
    "\n",
    "2)<b> Downward Closure Property:</b> If an itemset is infrequent, then its supersets are also infrequent. Thus the algorithm uses this property to reduce computation time and only check the itemsets whose subsets already satisfy the frequent candidate condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Generation(1-frequent itemset):\n",
    "We do pre pruning of the data by removing those items that already do not satisfy the minimum threshold. By downward closure property, the supersets will also be infrequent and hence we remove them from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre pruning step removing infrequent 1-itemset \n",
    "new_item_list={} #dict to hold item and transactions\n",
    "support_list={} #dict to hold item and support\n",
    "for i, (item, transactions) in enumerate(item_list.items()):\n",
    "    # check if support is greater than threshold\n",
    "    if (len(transactions)/(data_size))>=min_sup:\n",
    "        new_item_list[item] = transactions\n",
    "        support_list[item]=(round(len(transactions)/(data_size),2))\n",
    "e =E(new_item_list,set({}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-frequent itemset to generate other frequent candidate sets through Eclat:\n",
      "milk ['1', '2', '5', '6']  #SUP: 0.57\n",
      "bread ['2', '3', '4', '6', '7']  #SUP: 0.71\n",
      "jam ['2', '3', '4', '6', '7']  #SUP: 0.71\n",
      "butter ['2', '4', '5']  #SUP: 0.43\n"
     ]
    }
   ],
   "source": [
    "print(\"1-frequent itemset to generate other frequent candidate sets through Eclat:\")\n",
    "final_list =list(new_item_list.keys())\n",
    "final_trans = list(new_item_list.values())\n",
    "for i in range(0,len(final_list)):\n",
    "    print(final_list[i],final_trans[i],\" #SUP:\",support_list[final_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dot_1 denotes tree structure for eclat algorithm search\n",
    "dot_1 = Digraph(\"frequent itemset\")\n",
    "dot_1.node('root','root')\n",
    "for it,tr in item_list.items():\n",
    "    if (len(tr)/(data_size))>=min_sup:\n",
    "        dot_1.node(it,it)\n",
    "        dot_1.edge('root', it)\n",
    "    else:\n",
    "        dot_1.node(it,it,color='red')\n",
    "        dot_1.edge('root', it)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "Digraph is a python interface for drawing graphs and can be installed to include simple inline jupyter graphs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFS tree with 1-frequent itemsets:\n",
    "Those nodes which are red in color are infrequent and removed after the prepruning step. We observe that marmalade and spoon do not satisfy the minimum support threshold and is removed from the first step of frequent itemset generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: frequent itemset Pages: 1 -->\n",
       "<svg width=\"517pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 516.85 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>frequent itemset</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 512.8504,-112 512.8504,4 -4,4\"/>\n",
       "<!-- root -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>root</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"223.7444\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"223.7444\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- milk -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>milk</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"28.7444\" cy=\"-18\" rx=\"28.991\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"28.7444\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">milk</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;milk -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>root&#45;&gt;milk</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.957,-82.4146C167.7481,-72.6504 112.6588,-54.7031 66.7444,-36 64.8684,-35.2358 62.9526,-34.4258 61.0276,-33.5888\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"62.0228,-30.1977 51.4688,-29.2674 59.1391,-36.5762 62.0228,-30.1977\"/>\n",
       "</g>\n",
       "<!-- bread -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>bread</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"107.7444\" cy=\"-18\" rx=\"32.4634\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.7444\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bread</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;bread -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>root&#45;&gt;bread</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M203.8033,-77.6228C185.7466,-66.4151 158.8786,-49.7385 138.1459,-36.8698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.7353,-33.737 129.3931,-31.4371 136.0437,-39.6845 139.7353,-33.737\"/>\n",
       "</g>\n",
       "<!-- jam -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>jam</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"184.7444\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.7444\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">jam</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;jam -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>root&#45;&gt;jam</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M214.502,-72.937C209.7907,-64.2393 203.9627,-53.4799 198.7166,-43.7948\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"201.761,-42.0664 193.9206,-34.9405 195.6059,-45.4005 201.761,-42.0664\"/>\n",
       "</g>\n",
       "<!-- butter -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>butter</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"263.7444\" cy=\"-18\" rx=\"33.6247\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"263.7444\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">butter</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;butter -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>root&#45;&gt;butter</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233.2239,-72.937C237.9859,-64.3654 243.8604,-53.7914 249.1797,-44.2165\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252.2583,-45.882 254.0552,-35.4407 246.1391,-42.4825 252.2583,-45.882\"/>\n",
       "</g>\n",
       "<!-- marmalade -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>marmalade</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ff0000\" cx=\"368.7444\" cy=\"-18\" rx=\"53.8693\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"368.7444\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">marmalade</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;marmalade -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>root&#45;&gt;marmalade</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245.4524,-79.2209C267.5727,-68.237 302.37,-50.9583 329.3645,-37.5542\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.1538,-40.5735 338.5538,-32.9912 328.0406,-34.3039 331.1538,-40.5735\"/>\n",
       "</g>\n",
       "<!-- spoon -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>spoon</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ff0000\" cx=\"474.7444\" cy=\"-18\" rx=\"34.2123\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"474.7444\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">spoon</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;spoon -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>root&#45;&gt;spoon</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M249.7078,-84.5108C289.4171,-75.8362 367.4029,-57.6958 431.7444,-36 434.1601,-35.1854 436.6323,-34.2988 439.1106,-33.3702\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"440.5655,-36.5591 448.5925,-29.6439 438.0052,-30.0441 440.5655,-36.5591\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1155b1f98>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "The code below is used to ensure that sets maintain the order after any operation performed on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SO:https://stackoverflow.com/questions/1653970/does-python-have-an-ordered-set\n",
    "#SO:http://code.activestate.com/recipes/576694/\n",
    "import collections\n",
    "\n",
    "class OrderedSet(collections.MutableSet):\n",
    "\n",
    "    def __init__(self, iterable=None):\n",
    "        self.end = end = [] \n",
    "        end += [None, end, end]         # sentinel node for doubly linked list\n",
    "        self.map = {}                   # key --> [key, prev, next]\n",
    "        if iterable is not None:\n",
    "            self |= iterable\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.map)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return key in self.map\n",
    "\n",
    "    def add(self, key):\n",
    "        if key not in self.map:\n",
    "            end = self.end\n",
    "            curr = end[1]\n",
    "            curr[2] = end[1] = self.map[key] = [key, curr, end]\n",
    "\n",
    "    def discard(self, key):\n",
    "        if key in self.map:        \n",
    "            key, prev, next = self.map.pop(key)\n",
    "            prev[2] = next\n",
    "            next[1] = prev\n",
    "\n",
    "    def __iter__(self):\n",
    "        end = self.end\n",
    "        curr = end[2]\n",
    "        while curr is not end:\n",
    "            yield curr[0]\n",
    "            curr = curr[2]\n",
    "\n",
    "    def __reversed__(self):\n",
    "        end = self.end\n",
    "        curr = end[1]\n",
    "        while curr is not end:\n",
    "            yield curr[0]\n",
    "            curr = curr[1]\n",
    "\n",
    "    def pop(self, last=True):\n",
    "        if not self:\n",
    "            raise KeyError('set is empty')\n",
    "        key = self.end[1][0] if last else self.end[2][0]\n",
    "        self.discard(key)\n",
    "        return key\n",
    "\n",
    "    def __repr__(self):\n",
    "        if not self:\n",
    "            return '%s()' % (self.__class__.__name__,)\n",
    "        return '%s(%r)' % (self.__class__.__name__, list(self))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, OrderedSet):\n",
    "            return len(self) == len(other) and list(self) == list(other)\n",
    "        return set(self) == set(other)\n",
    "#SO:https://stackoverflow.com/questions/1653970/does-python-have-an-ordered-set\n",
    "#SO:http://code.activestate.com/recipes/576694/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECLAT IMPLEMENTATION:\n",
    "1) Candidate Generation is done by forming equivalence class and prefix<br>\n",
    "2) Pruning is done by comparison of the new itemset with minsup threshold\n",
    "\n",
    "Algorithm:\n",
    "Start with Eclat equivalence class E with prefix={} and all 1-frequent itemsets and transactions\n",
    "\n",
    "for all i in E:<br>\n",
    "&nbsp;    Fix prefix =Prefix $\\cup $ i <br>\n",
    "&nbsp;    initialise E_new as new equivalence class with prefix P <br>\n",
    "&nbsp;    for all j in E where j>i:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;     find the intersection of transaction of item i and j $ti\\cap tj$<br>\n",
    "&nbsp;&nbsp; &nbsp;     if the new itemset has support (length of transaction/total no of transactions) >= min sup:<br>\n",
    "&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;      E_new is now equivalence class with new itemset<br>\n",
    "&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;       Add the itemset $\\cup$ Prefix as frequent itemset<br>\n",
    "&nbsp;    if E_new is not null:<br>\n",
    "&nbsp;&nbsp;&nbsp; &nbsp;       recursively call function with E_new (Generate higher candidate itemsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Generation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Item/Prefix: milk\n",
      "Transaction List: OrderedSet(['1', '2', '5', '6'])\n",
      " \n",
      "Item under consideration bread\n",
      "Transaction list: OrderedSet(['2', '3', '4', '6', '7'])\n",
      "Intersected Transaction list: OrderedSet(['2', '6'])\n",
      " \n",
      "Item under consideration jam\n",
      "Transaction list: OrderedSet(['2', '3', '4', '6', '7'])\n",
      "Intersected Transaction list: OrderedSet(['2', '6'])\n",
      " \n",
      "Item under consideration butter\n",
      "Transaction list: OrderedSet(['2', '4', '5'])\n",
      "Intersected Transaction list: OrderedSet(['2', '5'])\n"
     ]
    }
   ],
   "source": [
    "def eclat_candidate(e):\n",
    "    prefix=e.prefix\n",
    "\n",
    "    for i, (item, transactions) in enumerate(e.item_set.items()):\n",
    "        # To show candidate generation for first item alone\n",
    "        if (i==1): break\n",
    "        # prefix = prefix U current_item\n",
    "        item_set = OrderedSet()\n",
    "        item_set.add(item)\n",
    "        prefix = e.prefix|(item_set) \n",
    "        list_prefix =list(prefix)\n",
    "        s1=','.join(list_prefix)\n",
    "        list_prefix=s1.split(\",\")\n",
    "        for l_pref in list_prefix:\n",
    "            l_pref=l_pref.strip()\n",
    "        # To ensure prefix is consistent\n",
    "        prefix =OrderedSet(list_prefix)\n",
    "        temp_set_i = OrderedSet() # hold transaction list of item i\n",
    "        for t in transactions:\n",
    "                    temp_set_i.add(t)\n",
    "        e_new = E({},prefix) # initialise new equivalence class with  current prefix \n",
    "        print(\"Current Item/Prefix:\",item)\n",
    "        print(\"Transaction List:\",temp_set_i)\n",
    "       \n",
    "        for j, (item, transactions) in enumerate(e.item_set.items()):\n",
    "            if j>i:\n",
    "                \n",
    "                temp_set = OrderedSet()#transaction list to compare with\n",
    "                for t in transactions:\n",
    "                    temp_set.add(t)\n",
    "                print(\" \")\n",
    "                print(\"Item under consideration\",item)\n",
    "                print(\"Transaction list:\", temp_set)\n",
    "                temp_set = (temp_set_i & temp_set)\n",
    "                print(\"Intersected Transaction list:\",temp_set)\n",
    "                \n",
    "eclat_candidate(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe below on how the program runs:<br>\n",
    "&nbsp;Candidate Generation:<br>\n",
    "&nbsp;&nbsp;&nbsp;1)Initially we pass the equivalence class {milk,bread,jam,butter|{}} with all 1-frequent itemsets with prefix {}<br>\n",
    "&nbsp;&nbsp;&nbsp;2)In the first pass it sets the prefix as milk and forms equivalence class {bread,milk,butter|milk} <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For every other item than milk,<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It performs the intersection of milk with current items bread,jam,butter as seen above.<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pruning:<br>\n",
    "     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If it satisfies the threshold then it would add to final list of frequent itemsets.\n",
    "     \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalence Class and Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_red ={}\n",
    "def eclat(e):\n",
    "    prefix=e.prefix\n",
    "\n",
    "    for i, (item, transactions) in enumerate(e.item_set.items()):\n",
    "        # prefix = prefix U current_item\n",
    "        \n",
    "        item_set = OrderedSet()\n",
    "        item_set.add(item)\n",
    "        prefix = e.prefix|(item_set)\n",
    "        # To ensure prefix is consistent\n",
    "        list_prefix =list(prefix)\n",
    "        s1=','.join(list_prefix)\n",
    "        list_prefix=s1.split(\",\")\n",
    "        for l_pref in list_prefix:\n",
    "            l_pref=l_pref.strip()\n",
    "        prefix =OrderedSet(list_prefix)\n",
    "        # hold transaction list of itemset i\n",
    "        temp_set_i = OrderedSet()\n",
    "        for t in transactions:\n",
    "                    temp_set_i.add(t)\n",
    "        # initialise new equivalence class with  current prefix \n",
    "        e_new = E({},prefix)\n",
    "        # to hold nodes of DFS tree\n",
    "        tree_list=[]\n",
    "        for j, (item, transactions) in enumerate(e.item_set.items()):\n",
    "            if j>i:\n",
    "                #transaction list of itemset under consideration\n",
    "                temp_set = OrderedSet()\n",
    "                for t in transactions:\n",
    "                    temp_set.add(t)\n",
    "                \n",
    "                temp_set = (temp_set_i & temp_set)\n",
    "                #Pruning- Check with min_sup value\n",
    "                if (len(temp_set)/data_size) >=min_sup:\n",
    "                    final_set = OrderedSet()\n",
    "                    final_set.add(item)\n",
    "                    # if condition satisfies add next level itemset to final frequent itemset\n",
    "                    l=list(prefix|(final_set))\n",
    "                    s=','.join(l)\n",
    "                    # Add itemset under consideration to new equivalence class\n",
    "                    # Downward closure property \n",
    "                    #If an itemset is infrequent,it is not added to equivalence class\n",
    "                    #Hence, it eliminates pruning process for those supersets\n",
    "                    e_new.item_set[item] = list(temp_set)\n",
    "                    set_new =OrderedSet()\n",
    "                    tree_list.append(s)\n",
    "                    # Final frequent itemset and transaction list\n",
    "                    final_list.append(s)\n",
    "                    final_trans.append(list(temp_set))\n",
    "                else:\n",
    "                    # If itemset does not satisfy the condition, add to tree as infrequent node\n",
    "                    tree_set = OrderedSet()\n",
    "                    tree_set.add(item)\n",
    "                    tree_red[','.join(list(prefix))]= ','.join(list(prefix|(tree_set)))\n",
    "                    \n",
    "        str1 = ','.join(list(prefix))\n",
    "        if(len(prefix)==1):\n",
    "            print(\" \")\n",
    "            print(\" \")\n",
    "        print(len(prefix),\"-itemset generation\")\n",
    "        print(\"Equivalence Class prefix:\",str1)\n",
    "        print(\"Equivalence Class:\", e_new.item_set)\n",
    "        print(\" \")\n",
    "        # Tree construction\n",
    "        for k in range(0,len(tree_list)):\n",
    "             #print(\"tree:\",tree_list[k])\n",
    "             dot_1.node(tree_list[k],tree_list[k])\n",
    "             dot_1.edge(str1,tree_list[k])\n",
    "        # recursive call of the algorithm to generate next level itemsets\n",
    "        if len(e_new.item_set)!=0:\n",
    "             eclat(e_new)\n",
    "        else:\n",
    "             continue\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "1 -itemset generation\n",
      "Equivalence Class prefix: milk\n",
      "Equivalence Class: {'bread': ['2', '6'], 'jam': ['2', '6'], 'butter': ['2', '5']}\n",
      " \n",
      "2 -itemset generation\n",
      "Equivalence Class prefix: milk,bread\n",
      "Equivalence Class: {'jam': ['2', '6']}\n",
      " \n",
      "3 -itemset generation\n",
      "Equivalence Class prefix: milk,bread,jam\n",
      "Equivalence Class: {}\n",
      " \n",
      "2 -itemset generation\n",
      "Equivalence Class prefix: milk,jam\n",
      "Equivalence Class: {}\n",
      " \n",
      "2 -itemset generation\n",
      "Equivalence Class prefix: milk,butter\n",
      "Equivalence Class: {}\n",
      " \n",
      " \n",
      " \n",
      "1 -itemset generation\n",
      "Equivalence Class prefix: bread\n",
      "Equivalence Class: {'jam': ['2', '3', '4', '6', '7'], 'butter': ['2', '4']}\n",
      " \n",
      "2 -itemset generation\n",
      "Equivalence Class prefix: bread,jam\n",
      "Equivalence Class: {'butter': ['2', '4']}\n",
      " \n",
      "3 -itemset generation\n",
      "Equivalence Class prefix: bread,jam,butter\n",
      "Equivalence Class: {}\n",
      " \n",
      "2 -itemset generation\n",
      "Equivalence Class prefix: bread,butter\n",
      "Equivalence Class: {}\n",
      " \n",
      " \n",
      " \n",
      "1 -itemset generation\n",
      "Equivalence Class prefix: jam\n",
      "Equivalence Class: {'butter': ['2', '4']}\n",
      " \n",
      "2 -itemset generation\n",
      "Equivalence Class prefix: jam,butter\n",
      "Equivalence Class: {}\n",
      " \n",
      " \n",
      " \n",
      "1 -itemset generation\n",
      "Equivalence Class prefix: butter\n",
      "Equivalence Class: {}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "eclat(e)\n",
    "        \n",
    "for root,child in tree_red.items():\n",
    "    #print(\"Tree red:\",root,child)\n",
    "    dot_1.node(child,child,color='red')\n",
    "    dot_1.edge(root,child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final View of DFS tree:\n",
    "Red nodes are infrequent. This tree represents the depth first search algorithm of eclat at every level/depth. The nodes that do not satisfy the minimum threshold are denoted in red and other nodes are the ones that are a part of the final frequent itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: frequent itemset Pages: 1 -->\n",
       "<svg width=\"1085pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 1084.61 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>frequent itemset</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 1080.6066,-256 1080.6066,4 -4,4\"/>\n",
       "<!-- root -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>root</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"791.5006\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"791.5006\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- milk -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>milk</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"434.5006\" cy=\"-162\" rx=\"28.991\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"434.5006\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">milk</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;milk -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>root&#45;&gt;milk</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M765.5385,-228.7639C703.2953,-216.2107 545.3387,-184.3539 472.4356,-169.6508\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"472.8127,-166.1564 462.3181,-167.6103 471.4288,-173.0183 472.8127,-166.1564\"/>\n",
       "</g>\n",
       "<!-- bread -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>bread</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"675.5006\" cy=\"-162\" rx=\"32.4634\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"675.5006\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bread</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;bread -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>root&#45;&gt;bread</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M771.5595,-221.6228C753.5028,-210.4151 726.6348,-193.7385 705.902,-180.8698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"707.4915,-177.737 697.1493,-175.4371 703.7999,-183.6845 707.4915,-177.737\"/>\n",
       "</g>\n",
       "<!-- jam -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>jam</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"752.5006\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"752.5006\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">jam</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;jam -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>root&#45;&gt;jam</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M782.2582,-216.937C777.5469,-208.2393 771.7189,-197.4799 766.4728,-187.7948\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"769.5171,-186.0664 761.6767,-178.9405 763.3621,-189.4005 769.5171,-186.0664\"/>\n",
       "</g>\n",
       "<!-- butter -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>butter</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"831.5006\" cy=\"-162\" rx=\"33.6247\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"831.5006\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">butter</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;butter -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>root&#45;&gt;butter</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M800.9801,-216.937C805.7421,-208.3654 811.6165,-197.7914 816.9359,-188.2165\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"820.0144,-189.882 821.8114,-179.4407 813.8953,-186.4825 820.0144,-189.882\"/>\n",
       "</g>\n",
       "<!-- marmalade -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>marmalade</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ff0000\" cx=\"936.5006\" cy=\"-162\" rx=\"53.8693\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"936.5006\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">marmalade</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;marmalade -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>root&#45;&gt;marmalade</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M813.2086,-223.2209C835.3288,-212.237 870.1262,-194.9583 897.1207,-181.5542\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"898.91,-184.5735 906.31,-176.9912 895.7968,-178.3039 898.91,-184.5735\"/>\n",
       "</g>\n",
       "<!-- spoon -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>spoon</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ff0000\" cx=\"1042.5006\" cy=\"-162\" rx=\"34.2123\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1042.5006\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">spoon</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;spoon -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>root&#45;&gt;spoon</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M817.4639,-228.5108C857.1733,-219.8362 935.1591,-201.6958 999.5006,-180 1001.9163,-179.1854 1004.3885,-178.2988 1006.8668,-177.3702\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1008.3217,-180.5591 1016.3487,-173.6439 1005.7614,-174.0441 1008.3217,-180.5591\"/>\n",
       "</g>\n",
       "<!-- milk,bread -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>milk,bread</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"234.5006\" cy=\"-90\" rx=\"52.7079\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5006\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">milk,bread</text>\n",
       "</g>\n",
       "<!-- milk&#45;&gt;milk,bread -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>milk&#45;&gt;milk,bread</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M409.5749,-153.0267C377.3612,-141.4298 320.6534,-121.015 280.5158,-106.5655\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"281.5428,-103.2154 270.9484,-103.1212 279.1718,-109.8016 281.5428,-103.2154\"/>\n",
       "</g>\n",
       "<!-- milk,jam -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>milk,jam</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"375.5006\" cy=\"-90\" rx=\"45.7828\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"375.5006\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">milk,jam</text>\n",
       "</g>\n",
       "<!-- milk&#45;&gt;milk,jam -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>milk&#45;&gt;milk,jam</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M421.1126,-145.6621C413.7083,-136.6263 404.3505,-125.2066 396.0407,-115.0658\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"398.7038,-112.7937 389.6584,-107.2773 393.2895,-117.2305 398.7038,-112.7937\"/>\n",
       "</g>\n",
       "<!-- milk,butter -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>milk,butter</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"492.5006\" cy=\"-90\" rx=\"53.8696\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"492.5006\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">milk,butter</text>\n",
       "</g>\n",
       "<!-- milk&#45;&gt;milk,butter -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>milk&#45;&gt;milk,butter</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M447.6617,-145.6621C454.8163,-136.7806 463.8261,-125.5959 471.8894,-115.5864\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"474.8306,-117.5144 478.3783,-107.5312 469.3793,-113.1231 474.8306,-117.5144\"/>\n",
       "</g>\n",
       "<!-- bread,jam -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>bread,jam</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"613.5006\" cy=\"-90\" rx=\"49.2572\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"613.5006\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bread,jam</text>\n",
       "</g>\n",
       "<!-- bread&#45;&gt;bread,jam -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>bread&#45;&gt;bread,jam</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M661.4319,-145.6621C653.651,-136.6263 643.8174,-125.2066 635.0851,-115.0658\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"637.5557,-112.5711 628.3783,-107.2773 632.2513,-117.1388 637.5557,-112.5711\"/>\n",
       "</g>\n",
       "<!-- bread,butter -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>bread,butter</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"738.5006\" cy=\"-90\" rx=\"57.3435\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"738.5006\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bread,butter</text>\n",
       "</g>\n",
       "<!-- bread&#45;&gt;bread,butter -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>bread&#45;&gt;bread,butter</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M689.7963,-145.6621C697.6453,-136.6918 707.5501,-125.372 716.375,-115.2865\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"719.2098,-117.3617 723.1608,-107.5312 713.9417,-112.7522 719.2098,-117.3617\"/>\n",
       "</g>\n",
       "<!-- jam,butter -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>jam,butter</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"864.5006\" cy=\"-90\" rx=\"50.4181\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"864.5006\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">jam,butter</text>\n",
       "</g>\n",
       "<!-- jam&#45;&gt;jam,butter -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>jam&#45;&gt;jam,butter</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M772.0095,-149.4586C788.3144,-138.9769 811.9294,-123.7958 831.216,-111.3973\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"833.2119,-114.2751 839.731,-105.9233 829.4266,-108.3868 833.2119,-114.2751\"/>\n",
       "</g>\n",
       "<!-- milk,bread,jam -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>milk,bread,jam</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"69.5006\" cy=\"-18\" rx=\"69.5012\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"69.5006\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">milk,bread,jam</text>\n",
       "</g>\n",
       "<!-- milk,bread&#45;&gt;milk,bread,jam -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>milk,bread&#45;&gt;milk,bread,jam</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M201.9019,-75.7751C176.9502,-64.8871 142.2435,-49.7424 114.6239,-37.6902\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"115.743,-34.3598 105.1777,-33.5682 112.9433,-40.7756 115.743,-34.3598\"/>\n",
       "</g>\n",
       "<!-- milk,bread,butter -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>milk,bread,butter</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ff0000\" cx=\"234.5006\" cy=\"-18\" rx=\"77.5878\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5006\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">milk,bread,butter</text>\n",
       "</g>\n",
       "<!-- milk,bread&#45;&gt;milk,bread,butter -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>milk,bread&#45;&gt;milk,bread,butter</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.5006,-71.8314C234.5006,-64.131 234.5006,-54.9743 234.5006,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.0007,-46.4132 234.5006,-36.4133 231.0007,-46.4133 238.0007,-46.4132\"/>\n",
       "</g>\n",
       "<!-- milk,jam,butter -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>milk,jam,butter</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ff0000\" cx=\"400.5006\" cy=\"-18\" rx=\"70.6626\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"400.5006\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">milk,jam,butter</text>\n",
       "</g>\n",
       "<!-- milk,jam&#45;&gt;milk,jam,butter -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>milk,jam&#45;&gt;milk,jam,butter</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M381.8092,-71.8314C384.5123,-64.0463 387.7322,-54.7729 390.7316,-46.1347\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"394.1333,-47.0081 394.1071,-36.4133 387.5206,-44.7119 394.1333,-47.0081\"/>\n",
       "</g>\n",
       "<!-- bread,jam,butter -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>bread,jam,butter</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"613.5006\" cy=\"-18\" rx=\"74.1374\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"613.5006\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bread,jam,butter</text>\n",
       "</g>\n",
       "<!-- bread,jam&#45;&gt;bread,jam,butter -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>bread,jam&#45;&gt;bread,jam,butter</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M613.5006,-71.8314C613.5006,-64.131 613.5006,-54.9743 613.5006,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"617.0007,-46.4132 613.5006,-36.4133 610.0007,-46.4133 617.0007,-46.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1155b1f98>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dot_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final list of frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets:\n",
      "milk ['1', '2', '5', '6'] SUP: 0.57\n",
      " \n",
      "bread ['2', '3', '4', '6', '7'] SUP: 0.71\n",
      " \n",
      "jam ['2', '3', '4', '6', '7'] SUP: 0.71\n",
      " \n",
      "butter ['2', '4', '5'] SUP: 0.43\n",
      " \n",
      "milk,bread ['2', '6'] SUP: 0.29\n",
      " \n",
      "milk,jam ['2', '6'] SUP: 0.29\n",
      " \n",
      "milk,butter ['2', '5'] SUP: 0.29\n",
      " \n",
      "milk,bread,jam ['2', '6'] SUP: 0.29\n",
      " \n",
      "bread,jam ['2', '3', '4', '6', '7'] SUP: 0.71\n",
      " \n",
      "bread,butter ['2', '4'] SUP: 0.29\n",
      " \n",
      "bread,jam,butter ['2', '4'] SUP: 0.29\n",
      " \n",
      "jam,butter ['2', '4'] SUP: 0.29\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Frequent itemsets:\")\n",
    "final_dict={}\n",
    "for i in range(0,len(final_list)):\n",
    "    print(final_list[i],final_trans[i],\"SUP:\",round(len(final_trans[i])/data_size,2))\n",
    "    #Itemset-transaction data of final list after candidate generation\n",
    "    final_dict[final_list[i]] = final_trans[i]\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rule Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every frequent itemset generated, check the confidence of every subset -> (itemset-subset).<br>\n",
    "If the confidence is greater than the minimum threshold, then we accept the association rule.<br>\n",
    "<br>\n",
    "Higher the confidence, it is more likely for purchase patterns to contain Y in transactions that contain item X.<br>\n",
    "<br>\n",
    "The association rules however do not imply causality. It suggests a co-occurence relationship between the LHS itemset(antecedent) and RHS itemset(consequent) in the rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter minimum confidence for the dataset:0.5\n"
     ]
    }
   ],
   "source": [
    "min_conf=float(input(\"Enter minimum confidence for the dataset:\"))\n",
    "#feed value used = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum confidence: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum confidence:\",min_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rule Generation Algorithm:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F- final set of frequent itemsets satisfying minimum threshold<br>\n",
    "for each f ⊂ F:(f ≠ F and f ≠ {})<br>\n",
    "&nbsp;&nbsp;&nbsp; find confidence conf of f as support(F)/support(f)<br>\n",
    "&nbsp;&nbsp;&nbsp; If conf >= min_conf:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Add association rule f -> (F-f)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final set of association rules:\n",
      " \n",
      "{'butter'} -> {'milk'} Confidence: 0.67\n",
      "{'jam'} -> {'bread'} Confidence: 1.0\n",
      "{'bread'} -> {'jam'} Confidence: 1.0\n",
      "{'butter'} -> {'bread'} Confidence: 0.67\n",
      "{'butter'} -> {'bread', 'jam'} Confidence: 0.67\n",
      "{'bread', 'butter'} -> {'jam'} Confidence: 1.0\n",
      "{'butter'} -> {'jam'} Confidence: 0.67\n"
     ]
    }
   ],
   "source": [
    "def findsubsets(S,m):\n",
    "    return set(itertools.combinations(S, m))\n",
    "print(\"Final set of association rules:\")\n",
    "print(\" \")\n",
    "for i in range(0,len(final_list)):\n",
    " s = set()\n",
    " # For all k-itemsets greater where k >1 \n",
    " if len(final_list[i].split(\",\"))>1:\n",
    "    #Creation of a set\n",
    "    current_set=(set(final_list[i].split(\",\")))\n",
    "    for j in final_list[i].split(\",\"):\n",
    "        s.add(j)\n",
    "    #print(i,s)\n",
    "    subset_list=[]\n",
    "    # Finding all possible subsets\n",
    "    for k in range(1,len(s)):\n",
    "        subset_list.append(list(findsubsets(s,k)))\n",
    "    #print(subset_list)\n",
    "    for i1 in (subset_list):\n",
    "        for j1 in range(0,len(i1)):\n",
    "           \n",
    "           if ','.join(i1[j1]) in final_dict.keys():\n",
    "            # for each subset ⊂ final_frequent_itemset\n",
    "            # find confidence as current itemset support/subset support\n",
    "            conf=(len(final_dict[final_list[i]])/len(final_dict[','.join(i1[j1])]))\n",
    "            # If it satisfies the minimum confidence threshold, print the association rule\n",
    "            if conf >min_conf:\n",
    "                print((set(i1[j1])),\"->\",current_set-set(i1[j1]),\"Confidence:\",round(conf,2))\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand Association Rule Mining at greater depth, do explore other algorithms like:<br>\n",
    "1) Apriori Algorithm<br>\n",
    "2) FP Growth Algorithm\n",
    "\n",
    "Pros and cons of Eclat Algorithm:<br>\n",
    "Pros:<br>\n",
    "Eclat, as an algorithm was developed to reduce the number of database scans that existed in Apriori algorithm. Thus it reduces the computation time.\n",
    "\n",
    "Cons:<br>\n",
    "With larger tid-sets (Transaction-id sets), eclat tends to occupy more space and time for intersection may increase. There are many studies that improvise the algorithm to minimise this disadvantage. For example, Bi-Eclat algorithm focuses on sorting the dataset based on support to reduce the intersections in case of long t-id sets. Parallelisation of algorithm also improves time and memory complexity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Association Rule Mining Basics: https://www-users.cs.umn.edu/~kumar001/dmbook/ch6.pdf<br>\n",
    " &nbsp;&nbsp;&nbsp;  https://www-users.cs.umn.edu/~kumar001/dmbook/dmslides/chap6_basic_association_analysis.pdf<br>\n",
    "2) Graphviz support: http://graphviz.readthedocs.io/en/stable/manual.html#jupyter-notebooks<br>\n",
    "3) Eclat: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=846291<br>\n",
    " &nbsp;&nbsp;&nbsp; Book - Advances in Machine Learning and Signal Processing: Proceedings of MALSIP 2015<br>\n",
    "4) Improvement Of Eclat Algorithm: https://pdfs.semanticscholar.org/ed12/8048b29c53ff640574446797edc4ba4ec088.pdf<br>\n",
    "5) Understanding Apriori,Eclat and FP Growth: https://www.slideshare.net/wanaezwani/apriori-and-eclat-algorithm-in-association-rule-mining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
